# DiffSynth Enhanced Image Generation System ğŸ¨

A comprehensive AI image generation and editing system combining Qwen-Image models with DiffSynth-Studio capabilities, featuring multiple frontends and optimized for high-end hardware.

> **ğŸš€ Latest**: Enhanced with DiffSynth-Studio integration, multiple frontend options, and organized project structure. Full CORS support for seamless web interface experience.

## âœ¨ Features

### Core Capabilities

- **ğŸ¯ Advanced Image Generation**: Text-to-image, image-to-image, inpainting, outpainting
- **ğŸ¨ DiffSynth Integration**: Professional-grade image editing with DiffSynth-Studio
- **ğŸ›ï¸ ControlNet Support**: Precise control over generation with various control types
- **ğŸŒ Multi-language Support**: English and Chinese text generation
- **âš¡ Hardware Optimized**: Specifically tuned for RTX 4080 + CUDA 12.1 setup

### User Interfaces

- **ğŸŒ Multiple Frontend Options**: Clean, Enhanced, Simple, and Docker-optimized HTML interfaces
- **âš™ï¸ FastAPI Backend**: RESTful API with comprehensive endpoints
- **ğŸ”„ Real-time Progress**: Job tracking and progress monitoring
- **ğŸ“± Responsive Design**: Works on desktop and mobile devices

### Technical Features

- **ğŸ”’ Local Deployment**: No cloud dependencies, complete privacy
- **ğŸ“Š Metadata Management**: Automatic saving of generation parameters
- **ğŸ”„ Resumable Downloads**: Smart model downloading with automatic resume
- **ğŸ›¡ï¸ CORS Support**: Seamless cross-origin requests for web interfaces
- **ğŸ§ª Comprehensive Testing**: Automated testing suite with integration tests

## ğŸ–¥ï¸ System Requirements

### Recommended Hardware

- **GPU**: RTX 4080 (16GB VRAM) or better
- **CPU**: AMD Threadripper or equivalent high-core-count processor
- **RAM**: 32GB minimum, 128GB recommended
- **Storage**: 60-70GB free space for models and generated images

### Software Requirements

- **OS**: Ubuntu 20.04+ or WSL2 with Ubuntu
- **Python**: 3.11 (standardized environment)
- **CUDA**: 12.1 or compatible
- **PyTorch**: 2.8.0+ with CUDA support

## ğŸš€ Quick Start

### **Initial Setup**

```bash
# 1. Clone the repository
git clone https://github.com/ramcana/qwen2.git
cd qwen2

# 2. Clone DiffSynth-Studio (required dependency)
git clone https://github.com/modelscope/DiffSynth-Studio.git

# 3. Create Python 3.11 virtual environment
python3.11 -m venv .venv311
source .venv311/bin/activate

# 4. Install dependencies
pip install -r requirements.txt

# 5. Install DiffSynth-Studio
cd DiffSynth-Studio
pip install -e .
cd ..
```

### **Launch the System**

```bash
# Start the enhanced API server
python src/api_server_diffsynth.py

# In another terminal, start the frontend server
python serve_frontend.py

# Access the web interface at:
# http://localhost:3001/frontend/html/clean_frontend.html
```

### **Alternative: Full System Startup**

```bash
# Start everything with one command
./start-full-system.sh

# Stop everything
./stop-full-system.sh
```

### **Available Frontends**

Choose the interface that best fits your needs:

1. **Clean Frontend** (Recommended):

   ```
   http://localhost:3001/frontend/html/clean_frontend.html
   ```

   - Modern, clean design
   - All features supported
   - Real-time progress tracking

2. **Enhanced Frontend**:

   ```
   http://localhost:3001/frontend/html/enhanced_frontend.html
   ```

   - Feature-rich interface
   - Advanced controls
   - React-based components

3. **Simple Frontend**:

   ```
   http://localhost:3001/frontend/html/simple_frontend.html
   ```

   - Minimal, fast interface
   - Basic functionality
   - Quick testing

4. **Docker Frontend**:
   ```
   http://localhost:3001/frontend/html/docker_frontend.html
   ```
   - Optimized for containerized deployment
   - Production-ready

### **Development Commands**

```bash
# Test the system
python tools/quick_test.py

# Run frontend tests
./scripts/run-frontend-tests.sh

# Debug performance issues
python tools/debug/debug_performance_issues.py

# Check model information
python tools/debug/check_model_info.py

# Start/stop full system
./start-full-system.sh
./stop-full-system.sh
```

## ğŸ“ Project Structure

```
qwen2/
â”œâ”€â”€ .venv311/                    # Python 3.11 virtual environment
â”œâ”€â”€ src/                         # Main application code
â”‚   â”œâ”€â”€ api_server_diffsynth.py  # Enhanced DiffSynth API server
â”‚   â”œâ”€â”€ api_server.py            # Original Qwen API server
â”‚   â”œâ”€â”€ diffsynth_service.py     # DiffSynth integration service
â”‚   â”œâ”€â”€ controlnet_service.py    # ControlNet integration
â”‚   â”œâ”€â”€ qwen_generator.py        # Core Qwen generation logic
â”‚   â””â”€â”€ utils/                   # Utility modules
â”œâ”€â”€ frontend/                    # Web interfaces
â”‚   â”œâ”€â”€ html/                    # HTML frontend files
â”‚   â”‚   â”œâ”€â”€ clean_frontend.html  # Clean, modern interface
â”‚   â”‚   â”œâ”€â”€ enhanced_frontend.html # Feature-rich interface
â”‚   â”‚   â”œâ”€â”€ simple_frontend.html # Basic interface
â”‚   â”‚   â””â”€â”€ docker_frontend.html # Docker-optimized interface
â”‚   â””â”€â”€ src/                     # React frontend (if using)
â”œâ”€â”€ tests/                       # Test suite
â”‚   â”œâ”€â”€ frontend/                # Frontend tests
â”‚   â”‚   â”œâ”€â”€ simple_test.html     # Basic API tests
â”‚   â”‚   â”œâ”€â”€ test_connection.html # Connection tests
â”‚   â”‚   â””â”€â”€ test_ui.html         # UI tests
â”‚   â””â”€â”€ *.py                     # Python test files
â”œâ”€â”€ tools/                       # Development tools
â”‚   â”œâ”€â”€ debug/                   # Debug utilities
â”‚   â”‚   â”œâ”€â”€ debug_performance_issues.py
â”‚   â”‚   â”œâ”€â”€ check_model_info.py
â”‚   â”‚   â””â”€â”€ check_model_size.py
â”‚   â””â”€â”€ quick_test.py            # Quick system test
â”œâ”€â”€ scripts/                     # Automation scripts
â”‚   â”œâ”€â”€ setup/                   # Setup scripts
â”‚   â”‚   â”œâ”€â”€ setup_ubuntu_native.sh
â”‚   â”‚   â””â”€â”€ diffsynth_qwen_setup.py
â”‚   â”œâ”€â”€ fix-frontend.sh          # Frontend fixes
â”‚   â””â”€â”€ run-frontend-tests.sh    # Frontend testing
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ troubleshooting/         # Troubleshooting guides
â”‚   â”‚   â”œâ”€â”€ WSL_CRASH_ANALYSIS.md
â”‚   â”‚   â”œâ”€â”€ CACHE_FIX_SUMMARY.md
â”‚   â”‚   â””â”€â”€ SOLUTION.md
â”‚   â”œâ”€â”€ DAILY_WORKFLOW.md        # Daily usage guide
â”‚   â””â”€â”€ integration_plan.md      # Integration documentation
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ docker/                  # Docker configurations
â”‚   â”‚   â”œâ”€â”€ docker-compose.prod.yml
â”‚   â”‚   â”œâ”€â”€ traefik.yml
â”‚   â”‚   â””â”€â”€ nginx.conf
â”‚   â””â”€â”€ *.json                   # JSON config files
â”œâ”€â”€ DiffSynth-Studio/            # External dependency (git clone)
â”œâ”€â”€ models/                      # Downloaded models
â”œâ”€â”€ generated_images/            # Output directory
â”œâ”€â”€ serve_frontend.py            # Frontend server utility
â”œâ”€â”€ start-full-system.sh         # System startup script
â”œâ”€â”€ stop-full-system.sh          # System shutdown script
â””â”€â”€ requirements.txt             # Pinned dependencies
```

## ğŸ’¡ Usage Examples

### Web Interface Usage

1. **Access the Clean Frontend**:

   ```
   http://localhost:3001/frontend/html/clean_frontend.html
   ```

2. **Generate Images**:

   - Enter your prompt: "A beautiful sunset over mountains"
   - Adjust parameters (width, height, steps, CFG scale)
   - Click "Generate Image"
   - Monitor progress in real-time

3. **Image Editing**:
   - Upload an input image
   - Select edit mode (Edit, Inpaint, Outpaint, Style Transfer)
   - Enter editing prompt
   - Generate enhanced image

### API Usage

```python
import requests
import base64
from PIL import Image
import io

# Text-to-Image Generation
response = requests.post("http://localhost:8000/api/generate/text-to-image", json={
    "prompt": "A beautiful sunset over mountains, digital art",
    "negative_prompt": "blurry, low quality",
    "width": 1024,
    "height": 1024,
    "steps": 20,
    "cfg_scale": 7.0
})

job_id = response.json()["job_id"]

# Monitor job progress
while True:
    status = requests.get(f"http://localhost:8000/api/jobs/{job_id}")
    job = status.json()
    if job["status"] == "completed":
        image_url = job["result"]["image_url"]
        break
```

### Image Editing with API

```python
# Convert image to base64
with open("input.jpg", "rb") as f:
    image_base64 = base64.b64encode(f.read()).decode()

# Edit image
response = requests.post("http://localhost:8000/api/edit/image", json={
    "prompt": "Add a rainbow in the sky",
    "operation": "edit",
    "image_base64": image_base64,
    "strength": 0.8,
    "steps": 20
})
```

## âš™ï¸ Configuration

### Hardware Optimization

The system automatically detects and optimizes for your hardware:

- **RTX 4080**: Uses float16 precision, memory optimization
- **CUDA 12.1**: Latest PyTorch with optimized CUDA kernels
- **High RAM**: Efficient model loading and caching

### Environment Features

- **ğŸ Python 3.11**: Standardized environment for consistency
- **ğŸ“¦ Pinned Dependencies**: Reproducible builds with exact versions
- **ğŸ”„ Resumable Downloads**: Smart model downloading with auto-resume
- **ğŸ§ª Smoke Testing**: Quick validation of complete pipeline
- **ğŸ› ï¸ Development Tools**: Integrated linting, formatting, and testing

### Model Information

- **Model**: Qwen/Qwen-Image-Edit
- **Size**: ~20GB total
- **Type**: Image editing and enhancement
- **Precision**: float16 for RTX 40-series GPUs
- **VRAM Usage**: ~12-15GB during inference

## ğŸ“Š Performance

### Expected Performance (RTX 4080)

| Operation        | Time        | VRAM Usage | Notes                 |
| ---------------- | ----------- | ---------- | --------------------- |
| Model Loading    | 30-60s      | 12GB       | One-time startup      |
| Image Editing    | 10-30s      | 15GB       | Depends on complexity |
| Batch Processing | 5-15s/image | 15GB       | Multiple edits        |

### Memory Usage

- **VRAM**: 12-15GB during inference
- **System RAM**: 8-12GB active usage
- **Storage**: ~2-5MB per generated image
- **Model Cache**: ~20GB for Qwen-Image-Edit

### Optimization Tips

- Use `torch.float16` for RTX 40-series GPUs
- Enable attention slicing for memory efficiency
- Keep VRAM usage under 14GB for stability
- Use the smoke test to verify optimal performance

## ğŸ”§ Troubleshooting

### Quick Diagnostics

```bash
# Test complete pipeline
make smoke

# Check system compatibility
python tools/test_device.py

# Emergency device fixes
python tools/emergency_device_fix.py
```

### Common Issues

1. **Model Download Stuck**:

   ```bash
   # Resume download
   make models
   ```

2. **CUDA Out of Memory**:

   ```bash
   # Clear GPU memory and restart
   make clean
   make smoke
   ```

3. **QwenImageEditPipeline not found**:

   ```bash
   # Reinstall latest diffusers
   source .venv311/bin/activate
   pip uninstall -y diffusers
   pip install git+https://github.com/huggingface/diffusers.git
   ```

4. **Environment Issues**:
   ```bash
   # Clean rebuild
   rm -rf .venv311
   make setup
   ```

### Resumable Downloads

If model download gets interrupted:

```bash
# Downloads automatically resume from where they left off
make models

# Check download progress
ls -la models/Qwen-Image-Edit/
du -sh models/Qwen-Image-Edit/
```

### Performance Issues

- **Slow generation**: Ensure CUDA is properly installed
- **Memory errors**: Use `torch.float16` precision
- **Crashes**: Run `make smoke` to validate setup

### Documentation

- ğŸ“– **Setup Guide**: [`SETUP.md`](SETUP.md) - Comprehensive setup instructions
- ğŸ”§ **Troubleshooting**: `docs/troubleshooting/` - Common issues and solutions
- ğŸŒ **Daily Workflow**: `docs/DAILY_WORKFLOW.md` - Usage patterns
- ğŸ“‹ **Integration Plan**: `docs/integration_plan.md` - System architecture

### Performance Tips

- **Frontend Server**: Use `python serve_frontend.py` for optimal CORS handling
- **API Health**: Check `http://localhost:8000/health` for system status
- **Memory Management**: Monitor GPU usage via API endpoints
- Use float16 precision for RTX 40-series GPUs
- Enable attention slicing for memory efficiency
- Keep VRAM usage under 14GB for stability

## ğŸš€ What's New

### âœ¨ Latest Updates (v3.0)

- **ğŸ¨ DiffSynth Integration**: Full DiffSynth-Studio integration with professional editing capabilities
- **ğŸŒ Multiple Frontends**: Clean, Enhanced, Simple, and Docker-optimized web interfaces
- **âš™ï¸ Enhanced API**: Comprehensive FastAPI backend with job tracking and progress monitoring
- **ğŸ›¡ï¸ CORS Support**: Seamless cross-origin requests for web interfaces
- **ğŸ“ Organized Structure**: Clean project organization with dedicated directories
- **ğŸ§ª Comprehensive Testing**: Frontend and backend testing suites

### ğŸ¯ Key Features

- **ğŸ”„ Real-time Progress**: Live job monitoring with progress updates
- **ğŸ›ï¸ ControlNet Support**: Advanced control over image generation
- **ğŸ“± Responsive Design**: Works on desktop and mobile devices
- **ğŸ”’ Local Privacy**: All processing happens on your hardware
- **âš¡ Hardware Optimized**: Tuned for RTX 4080 + CUDA 12.1
- **ğŸ› ï¸ Developer Friendly**: Organized codebase with comprehensive documentation

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Test your changes with `make smoke`
4. Run quality checks with `make lint` and `make format`
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Qwen Team**: For the amazing Qwen-Image-Edit model
- **Hugging Face**: For the diffusers library and model hosting
- **Gradio**: For the web interface framework
- **PyTorch Team**: For the excellent deep learning framework

---

## ğŸ”— Important Links

- **API Documentation**: `http://localhost:8000/docs` (when server is running)
- **Health Check**: `http://localhost:8000/health`
- **DiffSynth-Studio**: [GitHub Repository](https://github.com/modelscope/DiffSynth-Studio)
- **Frontend Server**: `http://localhost:3001`

## ğŸ“‹ Prerequisites

Before starting, ensure you have:

- **Git**: For cloning repositories
- **Python 3.11**: Required for the virtual environment
- **CUDA 12.1+**: For GPU acceleration
- **16GB+ VRAM**: RTX 4080 or equivalent
- **50GB+ Storage**: For models and generated images

---

**ğŸ¯ Hardware Optimized**: Specifically tuned for RTX 4080 + CUDA 12.1 setups  
**ğŸ”’ Local Privacy**: All processing happens on your hardware  
**âš¡ Production Ready**: Professional-quality image generation and editing  
**ğŸŒ Web-First**: Modern web interfaces with real-time progress tracking  
**ğŸ› ï¸ Developer Friendly**: Organized codebase with comprehensive testing
